{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJsGrqXzbVYH",
        "outputId": "471dc901-8e66-4b1b-f9ce-41e4b631df4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUT7eB9gbe8N",
        "outputId": "60eeaf1a-4a3e-4e2b-ad99-78f1f9e5a34f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read CSV file into DataFrame\n",
        "file_path = 'Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# combine the text columns\n",
        "df_combined = df.melt(id_vars=['Domain'], value_vars=['Human-generated text', 'ChatGPT-generated text', 'Mixed text'], value_name='All Text')\n"
      ],
      "metadata": {
        "id": "S7MnKLfXD6wN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove Citations & numbers\n",
        "import re\n",
        "\n",
        "def clean_text(texts):\n",
        "    cleaned_text = [re.sub(r'\\(.*?\\)|\\[\\d+(-\\d+)?\\]|\\s\\d+.*?\\s|\\s\\d+', '', text) for text in texts]\n",
        "    return cleaned_text\n",
        "\n",
        "df_combined['Clean Text'] = clean_text(df_combined['All Text'])\n",
        "print(df_combined['Clean Text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mud2L5vF2JnI",
        "outputId": "46197746-4ab3-4a67-df01-1befde47a18c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       WordNet reflects the relationship between word...\n",
            "1       Surprisingly perhaps, it was not untilthat the...\n",
            "2       Astronomy is without doubt the empirical scien...\n",
            "3       Galaxy clusters represent the largest class of...\n",
            "4       More puzzling are diffuse extended radio sourc...\n",
            "                              ...                        \n",
            "2995    As a measure of how divided the country can be...\n",
            "2996    In contrast to refugees, who have crossed an i...\n",
            "2997    The use of epidemiology in documenting the mor...\n",
            "2998    Haiti, situated in the Northern hemisphere, st...\n",
            "2999    The recognition of Posttraumatic Stress Disord...\n",
            "Name: Clean Text, Length: 3000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Min & Max Paragraphs Length\n",
        "\n",
        "# Define function to calculate word count statistics\n",
        "def word_stats(text_column):\n",
        "    max_lengths = []\n",
        "    min_lengths = []\n",
        "\n",
        "    for text in text_column:\n",
        "        paragraphs = text.split('\\n')\n",
        "        # Remove any empty or whitespace-only paragraphs\n",
        "        paragraphs = [p for p in paragraphs if p.strip()]\n",
        "        word_counts = [len(paragraph.split()) for paragraph in paragraphs]\n",
        "\n",
        "        # Determine the max and min word count for the text and add to the lists\n",
        "        max_lengths.append(max(word_counts, default=0))\n",
        "        min_lengths.append(min(word_counts, default=0))\n",
        "    return max(max_lengths), min(min_lengths)\n",
        "\n",
        "# Print overall max and min paragraph lengths\n",
        "max_length, min_length = word_stats(df_combined['Clean Text'])\n",
        "print(\"Overall:\")\n",
        "print(f\"Max Paragraph Length: {max_length} words\")\n",
        "print(f\"Min Paragraph Length: {min_length} words\")\n",
        "\n",
        "# Print max and min paragraph lengths per domain\n",
        "for domain, group in df_combined.groupby('Domain'):\n",
        "    max_length, min_length = word_stats(group['Clean Text'])\n",
        "    print(\"\\nDomain:\", domain)\n",
        "    print(f\"Max Paragraph Length: {max_length} words\")\n",
        "    print(f\"Min Paragraph Length: {min_length} words\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH57T4_sDUzb",
        "outputId": "5497711d-f8e1-43ac-ab60-8e79b4993c4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall:\n",
            "Max Paragraph Length: 490 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Astrophysics and Astronomy\n",
            "Max Paragraph Length: 287 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Climate Science and Environmental Studies\n",
            "Max Paragraph Length: 490 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Computer Science and Artificial Intelligence\n",
            "Max Paragraph Length: 430 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Genetics and Genomics\n",
            "Max Paragraph Length: 419 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Materials Science and Engineering\n",
            "Max Paragraph Length: 295 words\n",
            "Min Paragraph Length: 13 words\n",
            "\n",
            "Domain: Mathematics and Statistics\n",
            "Max Paragraph Length: 239 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Medical Research and Healthcare\n",
            "Max Paragraph Length: 320 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Natural Language Processing\n",
            "Max Paragraph Length: 402 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Neuroscience and Psychology\n",
            "Max Paragraph Length: 343 words\n",
            "Min Paragraph Length: 1 words\n",
            "\n",
            "Domain: Social Sciences and Humanities\n",
            "Max Paragraph Length: 254 words\n",
            "Min Paragraph Length: 1 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calculate AVG Paragraphs len.\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def paragraph_lengths(text_column):\n",
        "    lengths = []\n",
        "    for text in text_column:\n",
        "        paragraphs = text.split('\\n')\n",
        "        paragraphs = [p.strip() for p in paragraphs if p.strip()]  # remove blank lines\n",
        "        lengths.extend([len(p.split()) for p in paragraphs])\n",
        "    return lengths\n",
        "\n",
        "# Get the paragraph lengths for all the data\n",
        "all_lengths = paragraph_lengths(df_combined['Clean Text'])\n",
        "overall_avg_length = sum(all_lengths) / len(all_lengths) if all_lengths else 0\n",
        "\n",
        "# Get the paragraph lengths for each domain\n",
        "domain_avg_lengths = []\n",
        "for domain, group in df_combined.groupby('Domain'):\n",
        "    lengths = paragraph_lengths(group['Clean Text'])\n",
        "    avg_length = sum(lengths) / len(lengths) if lengths else 0\n",
        "    domain_avg_lengths.append(avg_length)\n",
        "\n",
        "\n",
        "# Normalize using Z-score\n",
        "all_avg_lengths = [overall_avg_length] + domain_avg_lengths\n",
        "z_scores = zscore(all_avg_lengths)\n",
        "\n",
        "print(f\"Overall:\")\n",
        "print(f\"Avg Paragraph Length: {overall_avg_length} words (Z-score {z_scores[0]})\\n\")\n",
        "\n",
        "for domain, avg_length, z_score in zip(df_combined['Domain'].unique(), domain_avg_lengths, z_scores[1:]):\n",
        "    print(f\"Domain: {domain}\")\n",
        "    print(f\"Avg Paragraph Length: {avg_length} words (Z-score {z_score})\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtJ0vr5JLQju",
        "outputId": "03c73f79-a028-4256-a7fc-b194d558e036"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall:\n",
            "Avg Paragraph Length: 34.87716992876409 words (Z-score -0.2961140621262857)\n",
            "\n",
            "Domain: Medical Research and Healthcare\n",
            "Avg Paragraph Length: 29.504332755632582 words (Z-score -0.5005848004156827)\n",
            "\n",
            "Domain: Astrophysics and Astronomy\n",
            "Avg Paragraph Length: 23.90556274256145 words (Z-score -0.7136537249328877)\n",
            "\n",
            "Domain: Climate Science and Environmental Studies\n",
            "Avg Paragraph Length: 30.55864069622876 words (Z-score -0.46046165578064274)\n",
            "\n",
            "Domain: Genetics and Genomics\n",
            "Avg Paragraph Length: 37.08015564202335 words (Z-score -0.21227639857606573)\n",
            "\n",
            "Domain: Neuroscience and Psychology\n",
            "Avg Paragraph Length: 101.66929133858268 words (Z-score 2.2457523552810312)\n",
            "\n",
            "Domain: Natural Language Processing\n",
            "Avg Paragraph Length: 23.447837150127228 words (Z-score -0.7310731044530804)\n",
            "\n",
            "Domain: Mathematics and Statistics\n",
            "Avg Paragraph Length: 21.28584729981378 words (Z-score -0.8133506138253066)\n",
            "\n",
            "Domain: Computer Science and Artificial Intelligence\n",
            "Avg Paragraph Length: 36.34679089026915 words (Z-score -0.24018560695045688)\n",
            "\n",
            "Domain: Materials Science and Engineering\n",
            "Avg Paragraph Length: 38.25561797752809 words (Z-score -0.16754255613357297)\n",
            "\n",
            "Domain: Social Sciences and Humanities\n",
            "Avg Paragraph Length: 92.30786026200873 words (Z-score 1.8894901679129479)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count uniqe words\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def unique_words(text_column):\n",
        "    return Counter(word.lower() for text in text_column for word in text.split() if word.lower() not in stopwords.words('english'))\n",
        "\n",
        "# Get unique words for the entire DataFrame\n",
        "unique_word_count = len(unique_words(df_combined['Clean Text']))\n",
        "\n",
        "print(\"\\nOverall:\")\n",
        "print(f\"Number of Unique Words (excluding stopwords): {unique_word_count}\")\n",
        "\n",
        "# Print number of unique words per domain, excluding stopwords\n",
        "for domain, group in df_combined.groupby('Domain'):\n",
        "    unique_word_count = len(unique_words(group['Clean Text']))\n",
        "    print(\"\\nDomain:\", domain)\n",
        "    print(f\"Number of Unique Words (excluding stopwords): {unique_word_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlwtkhVvHkze",
        "outputId": "2f676468-5c60-44ed-cb18-4b88670e32b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall:\n",
            "Number of Unique Words (excluding stopwords): 29151\n",
            "\n",
            "Domain: Astrophysics and Astronomy\n",
            "Number of Unique Words (excluding stopwords): 6790\n",
            "\n",
            "Domain: Climate Science and Environmental Studies\n",
            "Number of Unique Words (excluding stopwords): 7106\n",
            "\n",
            "Domain: Computer Science and Artificial Intelligence\n",
            "Number of Unique Words (excluding stopwords): 8266\n",
            "\n",
            "Domain: Genetics and Genomics\n",
            "Number of Unique Words (excluding stopwords): 5190\n",
            "\n",
            "Domain: Materials Science and Engineering\n",
            "Number of Unique Words (excluding stopwords): 3021\n",
            "\n",
            "Domain: Mathematics and Statistics\n",
            "Number of Unique Words (excluding stopwords): 1516\n",
            "\n",
            "Domain: Medical Research and Healthcare\n",
            "Number of Unique Words (excluding stopwords): 5540\n",
            "\n",
            "Domain: Natural Language Processing\n",
            "Number of Unique Words (excluding stopwords): 7126\n",
            "\n",
            "Domain: Neuroscience and Psychology\n",
            "Number of Unique Words (excluding stopwords): 5120\n",
            "\n",
            "Domain: Social Sciences and Humanities\n",
            "Number of Unique Words (excluding stopwords): 8908\n"
          ]
        }
      ]
    }
  ]
}